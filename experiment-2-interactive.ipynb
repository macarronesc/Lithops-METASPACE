{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Experiment 2: Interactive reprocessing\n",
    "This is representative of a new type of functionality that we currently don’t support in METASPACE\n",
    "because it’s uneconomical with the serverful approach. While looking for specific compounds,\n",
    "scientists tend to have relatively short lists of molecules of interest, and iteratively try\n",
    "different adducts or modifiers until they find the data they’re interested in.\n",
    "\n",
    "### METRICS TO BENCHMARK\n",
    "* Performance:\n",
    "    * **Metric:** Total processing time\n",
    "    \n",
    "        **Goal:** Fast enough to use interactively in a notebook - less than ~60 seconds\n",
    "\n",
    "* Cost:\n",
    "    * **Metric:** Total cost\n",
    "    \n",
    "        **Goal:** Significantly less than a full annotation - determined by experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook setup\n",
    "Run `python3 setup.py install` to install all requirements for annotation pipeline project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We need this to overcome Python notebooks limitations of too many open files\n",
    "import resource\n",
    "soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "print('Before:', soft, hard)\n",
    "\n",
    "# Raising the soft limit. Hard limits can be raised only by sudo users\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (10000, hard))\n",
    "soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "print('After:', soft, hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If pywren_ibm_cloud isn't installed, please run `pip install -e .` in this directory to install all dependencies\n",
    "import pywren_ibm_cloud as pywren\n",
    "\n",
    "pywren.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a socket timeout so that CF requests fail instead of hanging if they don't get a response\n",
    "import socket\n",
    "print('Previous timeout:', socket.getdefaulttimeout())\n",
    "socket.setdefaulttimeout(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "config = json.load(open('config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Input dataset\n",
    "input_ds = json.load(open('metabolomics/ds_config2.json'))\n",
    "# Input database (Used as a template. Some parameters overridden below...)\n",
    "input_db = json.load(open('metabolomics/db_config2.json'))\n",
    "\n",
    "# Override databases, because this experiment expects a small database\n",
    "exp_db_path = 'metabolomics/db/mol_db5.pickle'\n",
    "input_db['databases'] = [exp_db_path]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup (not included in benchmark timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotation_pipeline.molecular_db import upload_mol_db_from_file\n",
    "from annotation_pipeline.pipeline import Pipeline\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & segment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(config, input_ds, input_db, use_cache=False)\n",
    "pipeline.load_ds()\n",
    "pipeline.split_ds()\n",
    "pipeline.segment_ds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotation_pipeline.utils import get_ibm_cos_client\n",
    "cos_client = get_ibm_cos_client(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process new molecules and Run Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# Process new molecules:\n",
    "## Upload list of molecules (in a real scenario this list would change every iteration, so this isn't part of setup)\n",
    "upload_mol_db_from_file(config, config['storage']['db_bucket'], exp_db_path, 'metabolomics/db/mol_db5.csv')\n",
    "pipeline.build_database()\n",
    "pipeline.calculate_centroids()\n",
    "pipeline.segment_centroids()\n",
    "\n",
    "# Run Annotation:\n",
    "pipeline.annotate()\n",
    "results_df = pipeline.formula_metrics_df\n",
    "\n",
    "finish_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start', start_time)\n",
    "print('finish', finish_time)\n",
    "print('duration', finish_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display PyWren statistics file\n",
    "from annotation_pipeline.utils import get_pywren_stats\n",
    "get_pywren_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(results_df.shape)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Temp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.clean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}