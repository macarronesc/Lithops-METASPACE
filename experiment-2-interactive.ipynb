{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Experiment 2: Interactive reprocessing\n",
    "This is representative of a new type of functionality that we currently don’t support in METASPACE\n",
    "because it’s uneconomical with the serverful approach. While looking for specific compounds,\n",
    "scientists tend to have relatively short lists of molecules of interest, and iteratively try\n",
    "different adducts or modifiers until they find the data they’re interested in.\n",
    "\n",
    "## METRICS TO BENCHMARK\n",
    "* Performance:\n",
    "    * **Metric:** Total processing time\n",
    "    \n",
    "        **Goal:** Fast enough to use interactively in a notebook - less than ~60 seconds\n",
    "\n",
    "* Cost:\n",
    "    * **Metric:** Total cost\n",
    "    \n",
    "        **Goal:** Significantly less than a full annotation - determined by experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook setup\n",
    "Run `pip install -e .` in this directory to install all requirements for annotation pipeline project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "config = json.load(open('config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Input dataset\n",
    "input_ds = json.load(open('metabolomics/ds_config2.json'))\n",
    "# Input database (Used as a template. Some parameters overridden below...)\n",
    "input_db = json.load(open('metabolomics/db_config2.json'))\n",
    "\n",
    "# Override databases, because this experiment expects a small database\n",
    "exp_db_path = 'metabolomics/db/mol_db5.csv'\n",
    "input_db['databases'] = [exp_db_path]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup (not included in benchmark timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotation_pipeline.pipeline import Pipeline\n",
    "pipeline = Pipeline(config, input_ds, input_db, use_ds_cache=False, use_db_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & segment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upload_dataset()\n",
    "pipeline.load_ds()\n",
    "pipeline.split_ds()\n",
    "pipeline.segment_ds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Benchmark\n",
    "Process new molecules and Run Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Process new molecules:\n",
    "## Upload list of molecules (in a real scenario this list would change every iteration, so this isn't part of setup)\n",
    "pipeline.upload_molecular_databases()\n",
    "pipeline.build_database()\n",
    "pipeline.calculate_centroids()\n",
    "pipeline.segment_centroids()\n",
    "\n",
    "# Run Annotation:\n",
    "pipeline.annotate()\n",
    "results_df = pipeline.get_results()\n",
    "\n",
    "finish_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start', start_time)\n",
    "print('finish', finish_time)\n",
    "print('duration', finish_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistics file\n",
    "from annotation_pipeline.utils import PipelineStats\n",
    "PipelineStats.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(results_df.shape)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Temp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.clean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
